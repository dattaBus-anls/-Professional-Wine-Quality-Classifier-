
# ğŸ· Professional Wine Quality Classifier

Predict wine quality â€” **Poor / Average / Good** â€” from physicochemical properties using an end-to-end ML pipeline (training â†’ evaluation â†’ deployment).

**Live app:** https://4okshqzpjpsapep79xtmbs.streamlit.app/  
**Dataset:** https://www.kaggle.com/datasets/rajyellow46/wine-quality

---

## ğŸ§­ Project Layout 

```text

project_wine/
â”œâ”€ images/ # All generated charts & figures (PNG)
â”‚ â”œâ”€ alcohol_vs_volatile.png
â”‚ â”œâ”€ confusion_matrix.png
â”‚ â”œâ”€ correlation_heatmap.png
â”‚ â”œâ”€ cv_results.png
â”‚ â”œâ”€ feature_distribution-1.png
â”‚ â”œâ”€ feature_distribution-2.png
â”‚ â”œâ”€ feature_distribution-3.png
â”‚ â”œâ”€ feature_distribution-4.png
â”‚ â”œâ”€ feature_importance.png
â”‚ â”œâ”€ kmeans_elbow.png
â”‚ â”œâ”€ knn_validation_curve.png
â”‚ â””â”€ model vs weighted avg.png
â”œâ”€ models/ # Trained artifacts used by the app
â”‚ â”œâ”€ wine_model.pkl # Best model (Random Forest, balanced)
â”‚ â”œâ”€ wine_scaler.pkl # StandardScaler
â”‚ â”œâ”€ wine_label_encoder.pkl # Target encoder (Poor/Average/Good)
â”‚ â”œâ”€ wine_feature_names.pkl # Exact feature order
â”‚ â”œâ”€ wine_type_encoder.pkl # Red/White encoder
â”‚ â”œâ”€ feature_ranges.pkl # Input validation ranges
â”‚ â”œâ”€ dataset_stats.pkl # Training dataset summary
â”‚ â””â”€ model_performance.pkl # CV/Test metrics for dashboard
â”œâ”€ model_test_script.py # Quick sanity check for artifacts
â”œâ”€ wine_streamlit_app.py # Streamlit UI (loads from /models)
â”œâ”€ Wine_data_processing_model_training_testing.py # Training pipeline
â”œâ”€ winequalityN.csv # Kaggle dataset (6,497 rows)
â”œâ”€ requirements.txt # Python dependencies
â””â”€ Technical Report_Project_Wine.docx

```

## âš¡ Quick Start

```bash
# 1) Clone & enter
git clone https://github.com/dattaBus-anls/-Professional-Wine-Quality-Classifier-.git
cd project_wine

# 2) Install deps
pip install -r requirements.txt

# 3a) Re-train to regenerate artifacts
python Wine_data_processing_model_training_testing.py

# 3b) Or verify existing artifacts
python model_test_script.py

# 4) Run the app
streamlit run wine_streamlit_app.py

```

ğŸ¯ Highlights
Best Model: Random Forest (balanced class weights)

Test Accuracy: 82.2%

Cross-Validation: 81.8% Â± 1.8% (Stratified 5-fold)

KNN Tuning: Optimal k=1, euclidean (77.6% test)

Deployment: Streamlit Cloud (24/7), input validation, confidence bars

ğŸ§  Pipeline (Brief)
Preprocess: wine-type groupwise imputation; bucketize quality (Poor â‰¤4, Average 5â€“6, Good â‰¥7); standardize features

Balance: SMOTE on training folds to protect minority classes

Train & Compare: 16 models (LogReg, SVMs, KNN, Trees/Ensembles, NB) with 5-fold CV

Select & Persist: Choose by test accuracy + macro metrics â†’ save to models/

Serve: Streamlit app reproduces scaler + feature order; shows probabilities

ğŸ† Model Results (Top 5 by Test Accuracy)
Rank	Model	Test Acc	CV (mean Â± sd)
1	Random Forest (Balanced)	82.2%	81.8% Â± 1.8%
2	Random Forest	82.2%	81.8% Â± 1.8%
3	KNN (k=1, euclidean)	77.6%	78.5% Â± 1.5%
4	Decision Tree (Balanced)	73.4%	74.8% Â± 2.2%
5	SVM (RBF-Tuned)	71.1%	73.6% Â± 2.1%

## ğŸ–¼ï¸ Visual Gallery

![Correlation Heatmap](images/correlation_heatmap.png)

![KNN Validation Curve](images/knn_validation_curve.png)

![Cross-Validation Comparison](images/cv_results.png)

![Confusion Matrix (Best Model)](images/confusion_matrix.png)

![Random Forest Feature Importance](images/feature_importance.png)

![Alcohol vs. Volatile Acidity by Quality](images/alcohol_vs_volatile.png)

![K-Means Elbow](images/kmeans_elbow.png)

![Feature Distributions (1)](images/feature_distribution-1.png)
![Feature Distributions (2)](images/feature_distribution-2.png)
![Feature Distributions (3)](images/feature_distribution-3.png)
![Feature Distributions (4)](images/feature_distribution-4.png)
![Model vs Weighted Average](images/model_vs_weighted_avg.png)


ğŸ‘¤ Author

Apu Datta â€” MSBA, Baruch College (CUNY)
Live App: https://4okshqzpjpsapep79xtmbs.streamlit.app/

Last updated: Aug 2025

